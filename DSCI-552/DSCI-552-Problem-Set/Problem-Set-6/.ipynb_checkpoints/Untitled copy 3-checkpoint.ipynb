{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"datasets/ps6_trainvalid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>weather</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>291.870000</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>mist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01 14:00:00</td>\n",
       "      <td>291.868186</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01 15:00:00</td>\n",
       "      <td>291.862844</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01 16:00:00</td>\n",
       "      <td>291.857503</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  temperature  humidity  pressure       weather  \\\n",
       "0  2012-10-01 12:00:00          NaN       NaN       NaN           NaN   \n",
       "1  2012-10-01 13:00:00   291.870000      88.0    1013.0          mist   \n",
       "2  2012-10-01 14:00:00   291.868186      88.0    1013.0  sky is clear   \n",
       "3  2012-10-01 15:00:00   291.862844      88.0    1013.0  sky is clear   \n",
       "4  2012-10-01 16:00:00   291.857503      88.0    1013.0  sky is clear   \n",
       "\n",
       "   wind_direction  wind_speed  \n",
       "0             NaN         NaN  \n",
       "1             0.0         0.0  \n",
       "2             0.0         0.0  \n",
       "3             0.0         0.0  \n",
       "4             0.0         0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dealing with missing data\n",
    "missing_data = df[pd.isnull(df[\"temperature\"])]\n",
    "missing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those data\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df['datetime']\n",
    "temp_values = df['temperature'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44671,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44671,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([291.87      , 291.86818552, 291.86284446, ..., 296.51      ,\n",
       "       297.09      , 296.69      ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model which can forecast the 'future' 24 hours, 72 hours, ......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting future 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] [40 50]\n",
      "[30 40 50] [60 70]\n",
      "[50 60 70] [80 90]\n"
     ]
    }
   ],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    # for i in range(len(sequence)):\n",
    "    #     # find the end of this pattern\n",
    "    #     end_ix = i + n_steps_in\n",
    "    #     out_end_ix = end_ix + n_steps_out\n",
    "    #     # check if we are beyond the sequence\n",
    "    #     if out_end_ix > len(sequence):\n",
    "    #         break\n",
    "    #     # gather input and output parts of the pattern\n",
    "    #     seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "    #     X.append(seq_x)\n",
    "    #     y.append(seq_y)\n",
    "    i = 0\n",
    "    while i + n_steps_in + n_steps_out <= len(sequence):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = i + n_steps_in + n_steps_out\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        i += n_steps_out\n",
    "    return np.array(X), np.array(y)\n",
    " \n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "\tprint(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 24*5, 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_sequence(temp_values, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1856, 120)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1856, 120, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1856, 24)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[290.96, 292.28, 294.72, ..., 291.75, 294.55, 296.13],\n",
       "       [297.4 , 298.21, 298.01, ..., 293.54, 294.48, 296.44],\n",
       "       [296.83, 297.66, 297.68, ..., 291.25, 291.74, 293.93],\n",
       "       ...,\n",
       "       [291.58, 294.44, 296.58, ..., 290.15, 290.21, 290.41],\n",
       "       [291.26, 292.65, 293.98, ..., 285.3 , 285.08, 287.77],\n",
       "       [291.21, 293.38, 295.38, ..., 283.66, 284.14, 287.33]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training X: (1299, 120, 1)\n",
      "Shape of validation X: (557, 120, 1)\n",
      "Shape of training y: (1299, 24)\n",
      "Shape of validation y: (557, 24)\n"
     ]
    }
   ],
   "source": [
    "# Split training and validation set\n",
    "n = len(X)\n",
    "train_X = X[0:int(n*0.7),:]\n",
    "val_X = X[int(n*0.7):,:]\n",
    "\n",
    "train_y = y[0:int(n*0.7)]\n",
    "val_y = y[int(n*0.7):]\n",
    "\n",
    "print(\"Shape of training X: {}\".format(train_X.shape))\n",
    "print(\"Shape of validation X: {}\".format(val_X.shape))\n",
    "\n",
    "print(\"Shape of training y: {}\".format(train_y.shape))\n",
    "print(\"Shape of validation y: {}\".format(val_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "train_X_mean = train_X.mean()\n",
    "train_X_std = train_X.std()\n",
    "\n",
    "train_y_mean = train_y.mean()\n",
    "train_y_std = train_y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_train_X = (train_X - train_X_mean)/train_X_std\n",
    "normalized_val_X = (val_X - train_X_mean)/train_X_std\n",
    "\n",
    "normalized_train_y = (train_y - train_y_mean)/train_y_std\n",
    "normalized_val_y = (val_y - train_y_mean)/train_y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 120, 50)           10400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120, 24)           1224      \n",
      "=================================================================\n",
      "Total params: 11,624\n",
      "Trainable params: 11,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "RNN_model_2 = Sequential()\n",
    "RNN_model_2.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "RNN_model_2.add(LSTM(50, activation='relu'))\n",
    "RNN_model_2.add(Dense(n_steps_out))\n",
    "RNN_model_2.compile(optimizer='adam', loss='mse')\n",
    "print(RNN_model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Incompatible shapes: [32,120,24] vs. [32,24]\n\t [[node gradient_tape/mean_squared_error/BroadcastGradientArgs (defined at <ipython-input-33-e8b5242ba679>:2) ]] [Op:__inference_train_function_4328]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e8b5242ba679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mRNN_model_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_train_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_train_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [32,120,24] vs. [32,24]\n\t [[node gradient_tape/mean_squared_error/BroadcastGradientArgs (defined at <ipython-input-33-e8b5242ba679>:2) ]] [Op:__inference_train_function_4328]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "RNN_model_2.fit(normalized_train_X, normalized_train_y, epochs=100, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 3, 100)            40800     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 121,402\n",
      "Trainable params: 121,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif out_end_ix > len(sequence):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)\n",
    " \n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=50, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using humidity and pressure to predict temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y[0])\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temperature', 'humidity', 'pressure']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(df)[1:4]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45013, 7)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dealing with missing data\n",
    "missing_data = df[pd.isnull(df[cols])]\n",
    "missing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop those data\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 24 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_1 = ['temperature', 'humidity']\n",
    "cols_2 = ['temperature', 'pressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[cols_1].values\n",
    "df_2 = df[cols_2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using temperature and humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44551, 120, 2) (44551,)\n"
     ]
    }
   ],
   "source": [
    "X, y = split_sequences(df_1, n_steps)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = X.shape[2]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training X: (31185, 120, 2)\n",
      "Shape of validation X: (13366, 120, 2)\n",
      "Shape of training y: (31185,)\n",
      "Shape of validation y: (13366,)\n"
     ]
    }
   ],
   "source": [
    "# Split training and validation set\n",
    "n = len(X)\n",
    "train_X = X[0:int(n*0.7),:]\n",
    "val_X = X[int(n*0.7):,:]\n",
    "\n",
    "train_y = y[0:int(n*0.7)]\n",
    "val_y = y[int(n*0.7):]\n",
    "\n",
    "print(\"Shape of training X: {}\".format(train_X.shape))\n",
    "print(\"Shape of validation X: {}\".format(val_X.shape))\n",
    "\n",
    "print(\"Shape of training y: {}\".format(train_y.shape))\n",
    "print(\"Shape of validation y: {}\".format(val_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "train_X_mean = train_X.mean()\n",
    "train_X_std = train_X.std()\n",
    "\n",
    "train_y_mean = train_y.mean()\n",
    "train_y_std = train_y.std()\n",
    "\n",
    "normalized_train_X = (train_X - train_X_mean)/train_X_std\n",
    "normalized_val_X = (val_X - train_X_mean)/train_X_std\n",
    "\n",
    "normalized_train_y = (train_y - train_y_mean)/train_y_std\n",
    "normalized_val_y = (val_y - train_y_mean)/train_y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([290.13227985,  61.47520416])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = np.mean(train_X, axis=0)\n",
    "train_X_mean = np.mean(new_df, axis=0)\n",
    "train_X_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = np.std(train_X, axis=0)\n",
    "train_X_std = np.std(new_df, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290.1231005220199"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 10)                520       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 531\n",
      "Trainable params: 531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "RNN_model_2 = Sequential()\n",
    "RNN_model_2.add(LSTM(10, activation='relu', input_shape=(n_steps, n_features)))\n",
    "RNN_model_2.add(Dense(1))\n",
    "RNN_model_2.compile(optimizer='adam', loss='mse')\n",
    "print(RNN_model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "780/780 - 40s - loss: 1.0628 - val_loss: 0.8864\n",
      "Epoch 2/100\n",
      "780/780 - 34s - loss: 0.8661 - val_loss: 0.7579\n",
      "Epoch 3/100\n",
      "780/780 - 33s - loss: 0.8196 - val_loss: 0.7651\n",
      "Epoch 4/100\n",
      "780/780 - 33s - loss: 0.7566 - val_loss: 0.6854\n",
      "Epoch 5/100\n",
      "780/780 - 33s - loss: 0.6630 - val_loss: 0.5854\n",
      "Epoch 6/100\n",
      "780/780 - 33s - loss: 0.6105 - val_loss: 0.6007\n",
      "Epoch 7/100\n",
      "780/780 - 33s - loss: 0.5689 - val_loss: 0.5213\n",
      "Epoch 8/100\n",
      "780/780 - 33s - loss: 0.4805 - val_loss: 0.4093\n",
      "Epoch 9/100\n",
      "780/780 - 33s - loss: 0.6237 - val_loss: 0.5021\n",
      "Epoch 10/100\n",
      "780/780 - 33s - loss: 3.5239 - val_loss: 0.8978\n",
      "Epoch 11/100\n",
      "780/780 - 33s - loss: 0.8208 - val_loss: 0.7928\n",
      "Epoch 12/100\n",
      "780/780 - 33s - loss: 0.7976 - val_loss: 0.7765\n",
      "Epoch 13/100\n",
      "780/780 - 33s - loss: 0.7833 - val_loss: 0.7589\n",
      "Epoch 14/100\n",
      "780/780 - 33s - loss: 0.7682 - val_loss: 0.7405\n",
      "Epoch 15/100\n",
      "780/780 - 33s - loss: 0.7526 - val_loss: 0.7218\n",
      "Epoch 16/100\n",
      "780/780 - 33s - loss: 0.7367 - val_loss: 0.7032\n",
      "Epoch 17/100\n",
      "780/780 - 33s - loss: 0.7198 - val_loss: 0.6836\n",
      "Epoch 18/100\n",
      "780/780 - 33s - loss: 0.7011 - val_loss: 0.6609\n",
      "Epoch 19/100\n",
      "780/780 - 33s - loss: 0.6786 - val_loss: 0.6311\n",
      "Epoch 20/100\n",
      "780/780 - 33s - loss: 0.6503 - val_loss: 0.5955\n",
      "Epoch 21/100\n",
      "780/780 - 34s - loss: 0.6142 - val_loss: 0.5519\n",
      "Epoch 22/100\n",
      "780/780 - 33s - loss: 0.5719 - val_loss: 0.5016\n",
      "Epoch 23/100\n",
      "780/780 - 36s - loss: 0.5269 - val_loss: 0.4504\n",
      "Epoch 24/100\n",
      "780/780 - 39s - loss: 0.4868 - val_loss: 0.4082\n",
      "Epoch 25/100\n",
      "780/780 - 41s - loss: 0.4535 - val_loss: 0.3758\n",
      "Epoch 26/100\n",
      "780/780 - 35s - loss: 0.4263 - val_loss: 0.3501\n",
      "Epoch 27/100\n",
      "780/780 - 33s - loss: 0.4013 - val_loss: 0.3292\n",
      "Epoch 28/100\n",
      "780/780 - 34s - loss: 0.3770 - val_loss: 0.3092\n",
      "Epoch 29/100\n",
      "780/780 - 32s - loss: 0.3540 - val_loss: 0.3426\n",
      "Epoch 30/100\n",
      "780/780 - 32s - loss: 0.3269 - val_loss: 0.2702\n",
      "Epoch 31/100\n",
      "780/780 - 32s - loss: 0.3012 - val_loss: 0.2668\n",
      "Epoch 32/100\n",
      "780/780 - 32s - loss: 0.2780 - val_loss: 0.2356\n",
      "Epoch 33/100\n",
      "780/780 - 34s - loss: 0.2545 - val_loss: 0.2210\n",
      "Epoch 34/100\n",
      "780/780 - 33s - loss: 0.2323 - val_loss: 0.2225\n",
      "Epoch 35/100\n",
      "780/780 - 41s - loss: 0.2104 - val_loss: 0.1903\n",
      "Epoch 36/100\n",
      "780/780 - 36s - loss: 0.1925 - val_loss: 0.1745\n",
      "Epoch 37/100\n",
      "780/780 - 35s - loss: 0.1764 - val_loss: 0.1583\n",
      "Epoch 38/100\n",
      "780/780 - 40s - loss: 0.1621 - val_loss: 0.1499\n",
      "Epoch 39/100\n",
      "780/780 - 44s - loss: 0.1500 - val_loss: 0.1406\n",
      "Epoch 40/100\n",
      "780/780 - 35s - loss: 0.1367 - val_loss: 0.1331\n",
      "Epoch 41/100\n",
      "780/780 - 37s - loss: 0.1261 - val_loss: 0.1318\n",
      "Epoch 42/100\n",
      "780/780 - 51s - loss: 0.1155 - val_loss: 0.1219\n",
      "Epoch 43/100\n",
      "780/780 - 36s - loss: 0.1027 - val_loss: 0.1088\n",
      "Epoch 44/100\n",
      "780/780 - 37s - loss: 0.0915 - val_loss: 0.1341\n",
      "Epoch 45/100\n",
      "780/780 - 42s - loss: 0.0871 - val_loss: 0.0977\n",
      "Epoch 46/100\n",
      "780/780 - 40s - loss: 0.0835 - val_loss: 0.1003\n",
      "Epoch 47/100\n",
      "780/780 - 38s - loss: 0.0777 - val_loss: 0.0879\n",
      "Epoch 48/100\n",
      "780/780 - 38s - loss: 0.0736 - val_loss: 0.0798\n",
      "Epoch 49/100\n",
      "780/780 - 43s - loss: 0.0687 - val_loss: 0.0759\n",
      "Epoch 50/100\n",
      "780/780 - 43s - loss: 0.0644 - val_loss: 0.0729\n",
      "Epoch 51/100\n",
      "780/780 - 38s - loss: 0.0594 - val_loss: 0.0682\n",
      "Epoch 52/100\n",
      "780/780 - 35s - loss: 0.0583 - val_loss: 0.0669\n",
      "Epoch 53/100\n",
      "780/780 - 41s - loss: 0.0568 - val_loss: 0.0715\n",
      "Epoch 54/100\n",
      "780/780 - 43s - loss: 0.0563 - val_loss: 0.0700\n",
      "Epoch 55/100\n",
      "780/780 - 39s - loss: 0.0558 - val_loss: 0.0652\n",
      "Epoch 56/100\n",
      "780/780 - 38s - loss: 0.0554 - val_loss: 0.0721\n",
      "Epoch 57/100\n",
      "780/780 - 42s - loss: 0.0545 - val_loss: 0.0649\n",
      "Epoch 58/100\n",
      "780/780 - 37s - loss: 0.0540 - val_loss: 0.0623\n",
      "Epoch 59/100\n",
      "780/780 - 40s - loss: 0.0530 - val_loss: 0.0627\n",
      "Epoch 60/100\n",
      "780/780 - 39s - loss: 0.0527 - val_loss: 0.0642\n",
      "Epoch 61/100\n",
      "780/780 - 33s - loss: 0.0525 - val_loss: 0.0622\n",
      "Epoch 62/100\n",
      "780/780 - 39s - loss: 0.0520 - val_loss: 0.0619\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-e8b5242ba679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mRNN_model_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_train_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_train_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "RNN_model_2.fit(normalized_train_X, normalized_train_y, epochs=100, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using temperature and pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[291.87      ],\n",
       "       [291.86818552],\n",
       "       [291.86284446],\n",
       "       ...,\n",
       "       [296.51      ],\n",
       "       [297.09      ],\n",
       "       [296.69      ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = temp_values.reshape(-1,1) \n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44671, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization is optional but recommended for neural network as certain \n",
    "# activation functions are sensitive to magnitude of numbers. \n",
    "# normalize the datasets\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) #Also try QuantileTransformer\n",
    "new_temp = scaler.fit_transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (31269, 1)\n",
      "Shape of validation data: (13402, 1)\n"
     ]
    }
   ],
   "source": [
    "n = len(new_temp)\n",
    "train_data = new_temp[0:int(n*0.7),:]\n",
    "val_data = new_temp[int(n*0.7):,:]\n",
    "\n",
    "print(\"Shape of training data: {}\".format(train_data.shape))\n",
    "print(\"Shape of validation data: {}\".format(val_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq_size is the number of previous time steps to use as \n",
    "#input variables to predict the next time period.\n",
    "\n",
    "#creates a dataset where X is the number of passengers at a given time (t, t-1, t-2...) \n",
    "#and Y is the number of passengers at the next time (t + 1).\n",
    "\n",
    "def to_sequences(dataset, window_size=1):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(dataset)-window_size-1):\n",
    "#         print(i)\n",
    "        window = dataset[i:(i+window_size), 0]\n",
    "        x.append(window)\n",
    "#         print(x)\n",
    "        y.append(dataset[i+window_size, 0])\n",
    "#         print(y)\n",
    "        \n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3],\n",
       "        [3, 4],\n",
       "        [4, 5],\n",
       "        [5, 6],\n",
       "        [6, 7],\n",
       "        [7, 8]]),\n",
       " array([2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "example_data = example_data.reshape(-1, 1)\n",
    "\n",
    "to_sequences(example_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set: (31148, 120)\n",
      "Shape of validation set: (13281, 120)\n"
     ]
    }
   ],
   "source": [
    "window_size = 24*5 # Number of time steps to look back \n",
    "#Larger sequences (look further back) may improve forecasting.\n",
    "train_X, train_Y = to_sequences(train_data, window_size)\n",
    "val_X, val_Y = to_sequences(val_data, window_size)\n",
    "\n",
    "#Compare trainX and dataset. You can see that X= values at t, t+1 and t+2\n",
    "#whereas Y is the value that follows, t+3 (since our sequence size is 3)\n",
    "\n",
    "print(\"Shape of training set: {}\".format(train_X.shape))\n",
    "print(\"Shape of validation set: {}\".format(val_X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build deep model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'window_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-96df78929656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# create and fit dense model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'window_size' is not defined"
     ]
    }
   ],
   "source": [
    "#Input dimensions are... (N x seq_size)\n",
    "print('Build deep model...')\n",
    "# create and fit dense model\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=window_size, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics = ['acc'])\n",
    "monitor = EarlyStopping(monitor='val_loss', patience=20)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "974/974 - 3s - loss: 0.0082 - acc: 3.2105e-05 - val_loss: 0.0020 - val_acc: 7.5296e-05\n",
      "Epoch 2/100\n",
      "974/974 - 1s - loss: 0.0021 - acc: 3.2105e-05 - val_loss: 0.0012 - val_acc: 7.5296e-05\n",
      "Epoch 3/100\n",
      "974/974 - 1s - loss: 0.0015 - acc: 3.2105e-05 - val_loss: 9.9564e-04 - val_acc: 7.5296e-05\n",
      "Epoch 4/100\n",
      "974/974 - 1s - loss: 0.0011 - acc: 3.2105e-05 - val_loss: 6.5412e-04 - val_acc: 7.5296e-05\n",
      "Epoch 5/100\n",
      "974/974 - 1s - loss: 9.1442e-04 - acc: 3.2105e-05 - val_loss: 6.3302e-04 - val_acc: 7.5296e-05\n",
      "Epoch 6/100\n",
      "974/974 - 1s - loss: 8.5439e-04 - acc: 3.2105e-05 - val_loss: 6.7036e-04 - val_acc: 7.5296e-05\n",
      "Epoch 7/100\n",
      "974/974 - 1s - loss: 7.7975e-04 - acc: 3.2105e-05 - val_loss: 4.5673e-04 - val_acc: 7.5296e-05\n",
      "Epoch 8/100\n",
      "974/974 - 1s - loss: 7.2087e-04 - acc: 3.2105e-05 - val_loss: 4.6757e-04 - val_acc: 7.5296e-05\n",
      "Epoch 9/100\n",
      "974/974 - 1s - loss: 6.9390e-04 - acc: 3.2105e-05 - val_loss: 4.1291e-04 - val_acc: 7.5296e-05\n",
      "Epoch 10/100\n",
      "974/974 - 1s - loss: 6.6921e-04 - acc: 3.2105e-05 - val_loss: 5.2743e-04 - val_acc: 7.5296e-05\n",
      "Epoch 11/100\n",
      "974/974 - 1s - loss: 6.4867e-04 - acc: 3.2105e-05 - val_loss: 5.6514e-04 - val_acc: 7.5296e-05\n",
      "Epoch 12/100\n",
      "974/974 - 1s - loss: 6.3018e-04 - acc: 3.2105e-05 - val_loss: 4.0714e-04 - val_acc: 7.5296e-05\n",
      "Epoch 13/100\n",
      "974/974 - 1s - loss: 6.2799e-04 - acc: 3.2105e-05 - val_loss: 3.5413e-04 - val_acc: 7.5296e-05\n",
      "Epoch 14/100\n",
      "974/974 - 1s - loss: 6.0562e-04 - acc: 3.2105e-05 - val_loss: 4.6061e-04 - val_acc: 7.5296e-05\n",
      "Epoch 15/100\n",
      "974/974 - 1s - loss: 6.0277e-04 - acc: 3.2105e-05 - val_loss: 6.1680e-04 - val_acc: 7.5296e-05\n",
      "Epoch 16/100\n",
      "974/974 - 1s - loss: 5.8514e-04 - acc: 3.2105e-05 - val_loss: 4.5917e-04 - val_acc: 7.5296e-05\n",
      "Epoch 17/100\n",
      "974/974 - 1s - loss: 5.9613e-04 - acc: 3.2105e-05 - val_loss: 5.5028e-04 - val_acc: 7.5296e-05\n",
      "Epoch 18/100\n",
      "974/974 - 1s - loss: 5.8027e-04 - acc: 3.2105e-05 - val_loss: 3.5805e-04 - val_acc: 7.5296e-05\n",
      "Epoch 19/100\n",
      "974/974 - 1s - loss: 5.7961e-04 - acc: 3.2105e-05 - val_loss: 7.8864e-04 - val_acc: 7.5296e-05\n",
      "Epoch 20/100\n",
      "974/974 - 1s - loss: 5.6648e-04 - acc: 3.2105e-05 - val_loss: 3.4840e-04 - val_acc: 7.5296e-05\n",
      "Epoch 21/100\n",
      "974/974 - 1s - loss: 5.5743e-04 - acc: 3.2105e-05 - val_loss: 3.8347e-04 - val_acc: 7.5296e-05\n",
      "Epoch 22/100\n",
      "974/974 - 1s - loss: 5.7804e-04 - acc: 3.2105e-05 - val_loss: 3.2396e-04 - val_acc: 7.5296e-05\n",
      "Epoch 23/100\n",
      "974/974 - 1s - loss: 5.5478e-04 - acc: 3.2105e-05 - val_loss: 3.7549e-04 - val_acc: 7.5296e-05\n",
      "Epoch 24/100\n",
      "974/974 - 1s - loss: 5.5016e-04 - acc: 3.2105e-05 - val_loss: 4.8712e-04 - val_acc: 7.5296e-05\n",
      "Epoch 25/100\n",
      "974/974 - 1s - loss: 5.4834e-04 - acc: 3.2105e-05 - val_loss: 3.2205e-04 - val_acc: 7.5296e-05\n",
      "Epoch 26/100\n",
      "974/974 - 1s - loss: 5.4800e-04 - acc: 3.2105e-05 - val_loss: 3.7512e-04 - val_acc: 7.5296e-05\n",
      "Epoch 27/100\n",
      "974/974 - 1s - loss: 5.5169e-04 - acc: 3.2105e-05 - val_loss: 3.2114e-04 - val_acc: 7.5296e-05\n",
      "Epoch 28/100\n",
      "974/974 - 1s - loss: 5.4723e-04 - acc: 3.2105e-05 - val_loss: 3.6721e-04 - val_acc: 7.5296e-05\n",
      "Epoch 29/100\n",
      "974/974 - 1s - loss: 5.3977e-04 - acc: 3.2105e-05 - val_loss: 3.1507e-04 - val_acc: 7.5296e-05\n",
      "Epoch 30/100\n",
      "974/974 - 1s - loss: 5.4049e-04 - acc: 3.2105e-05 - val_loss: 3.4757e-04 - val_acc: 7.5296e-05\n",
      "Epoch 31/100\n",
      "974/974 - 1s - loss: 5.3658e-04 - acc: 3.2105e-05 - val_loss: 3.0895e-04 - val_acc: 7.5296e-05\n",
      "Epoch 32/100\n",
      "974/974 - 1s - loss: 5.4935e-04 - acc: 3.2105e-05 - val_loss: 3.2077e-04 - val_acc: 7.5296e-05\n",
      "Epoch 33/100\n",
      "974/974 - 1s - loss: 5.4141e-04 - acc: 3.2105e-05 - val_loss: 5.9479e-04 - val_acc: 7.5296e-05\n",
      "Epoch 34/100\n",
      "974/974 - 1s - loss: 5.4474e-04 - acc: 3.2105e-05 - val_loss: 3.0992e-04 - val_acc: 7.5296e-05\n",
      "Epoch 35/100\n",
      "974/974 - 1s - loss: 5.3168e-04 - acc: 3.2105e-05 - val_loss: 3.3472e-04 - val_acc: 7.5296e-05\n",
      "Epoch 36/100\n",
      "974/974 - 1s - loss: 5.2983e-04 - acc: 3.2105e-05 - val_loss: 3.0955e-04 - val_acc: 7.5296e-05\n",
      "Epoch 37/100\n",
      "974/974 - 1s - loss: 5.4371e-04 - acc: 3.2105e-05 - val_loss: 6.0198e-04 - val_acc: 7.5296e-05\n",
      "Epoch 38/100\n",
      "974/974 - 1s - loss: 5.3208e-04 - acc: 3.2105e-05 - val_loss: 3.4378e-04 - val_acc: 7.5296e-05\n",
      "Epoch 39/100\n",
      "974/974 - 1s - loss: 5.2880e-04 - acc: 3.2105e-05 - val_loss: 4.4613e-04 - val_acc: 7.5296e-05\n",
      "Epoch 40/100\n",
      "974/974 - 1s - loss: 5.3669e-04 - acc: 3.2105e-05 - val_loss: 3.2493e-04 - val_acc: 7.5296e-05\n",
      "Epoch 41/100\n",
      "974/974 - 1s - loss: 5.2982e-04 - acc: 3.2105e-05 - val_loss: 3.8600e-04 - val_acc: 7.5296e-05\n",
      "Epoch 42/100\n",
      "974/974 - 1s - loss: 5.3745e-04 - acc: 3.2105e-05 - val_loss: 3.1999e-04 - val_acc: 7.5296e-05\n",
      "Epoch 43/100\n",
      "974/974 - 1s - loss: 5.3626e-04 - acc: 3.2105e-05 - val_loss: 3.0702e-04 - val_acc: 7.5296e-05\n",
      "Epoch 44/100\n",
      "974/974 - 1s - loss: 5.1863e-04 - acc: 3.2105e-05 - val_loss: 3.2987e-04 - val_acc: 7.5296e-05\n",
      "Epoch 45/100\n",
      "974/974 - 1s - loss: 5.2677e-04 - acc: 3.2105e-05 - val_loss: 3.1462e-04 - val_acc: 7.5296e-05\n",
      "Epoch 46/100\n",
      "974/974 - 1s - loss: 5.2638e-04 - acc: 3.2105e-05 - val_loss: 3.9801e-04 - val_acc: 7.5296e-05\n",
      "Epoch 47/100\n",
      "974/974 - 1s - loss: 5.2419e-04 - acc: 3.2105e-05 - val_loss: 3.0430e-04 - val_acc: 7.5296e-05\n",
      "Epoch 48/100\n",
      "974/974 - 1s - loss: 5.3450e-04 - acc: 3.2105e-05 - val_loss: 3.0648e-04 - val_acc: 7.5296e-05\n",
      "Epoch 49/100\n",
      "974/974 - 1s - loss: 5.3252e-04 - acc: 3.2105e-05 - val_loss: 3.9499e-04 - val_acc: 7.5296e-05\n",
      "Epoch 50/100\n",
      "974/974 - 1s - loss: 5.2660e-04 - acc: 3.2105e-05 - val_loss: 3.4548e-04 - val_acc: 7.5296e-05\n",
      "Epoch 51/100\n",
      "974/974 - 1s - loss: 5.3329e-04 - acc: 3.2105e-05 - val_loss: 3.1521e-04 - val_acc: 7.5296e-05\n",
      "Epoch 52/100\n",
      "974/974 - 1s - loss: 5.2679e-04 - acc: 3.2105e-05 - val_loss: 3.2952e-04 - val_acc: 7.5296e-05\n",
      "Epoch 53/100\n",
      "974/974 - 1s - loss: 5.2506e-04 - acc: 3.2105e-05 - val_loss: 3.6143e-04 - val_acc: 7.5296e-05\n",
      "Epoch 54/100\n",
      "974/974 - 1s - loss: 5.2637e-04 - acc: 3.2105e-05 - val_loss: 3.0982e-04 - val_acc: 7.5296e-05\n",
      "Epoch 55/100\n",
      "974/974 - 1s - loss: 5.2843e-04 - acc: 3.2105e-05 - val_loss: 3.4963e-04 - val_acc: 7.5296e-05\n",
      "Epoch 56/100\n",
      "974/974 - 1s - loss: 5.3191e-04 - acc: 3.2105e-05 - val_loss: 3.6133e-04 - val_acc: 7.5296e-05\n",
      "Epoch 57/100\n",
      "974/974 - 1s - loss: 5.2514e-04 - acc: 3.2105e-05 - val_loss: 4.8125e-04 - val_acc: 7.5296e-05\n",
      "Epoch 58/100\n",
      "974/974 - 1s - loss: 5.2842e-04 - acc: 3.2105e-05 - val_loss: 3.1328e-04 - val_acc: 7.5296e-05\n",
      "Epoch 59/100\n",
      "974/974 - 1s - loss: 5.2064e-04 - acc: 3.2105e-05 - val_loss: 3.1470e-04 - val_acc: 7.5296e-05\n",
      "Epoch 60/100\n",
      "974/974 - 1s - loss: 5.2924e-04 - acc: 3.2105e-05 - val_loss: 3.5644e-04 - val_acc: 7.5296e-05\n",
      "Epoch 61/100\n",
      "974/974 - 1s - loss: 5.2745e-04 - acc: 3.2105e-05 - val_loss: 5.0891e-04 - val_acc: 7.5296e-05\n",
      "Epoch 62/100\n",
      "974/974 - 1s - loss: 5.2352e-04 - acc: 3.2105e-05 - val_loss: 3.6909e-04 - val_acc: 7.5296e-05\n",
      "Epoch 63/100\n",
      "974/974 - 1s - loss: 5.1708e-04 - acc: 3.2105e-05 - val_loss: 6.7804e-04 - val_acc: 7.5296e-05\n",
      "Epoch 64/100\n",
      "974/974 - 1s - loss: 5.2670e-04 - acc: 3.2105e-05 - val_loss: 3.0319e-04 - val_acc: 7.5296e-05\n",
      "Epoch 65/100\n",
      "974/974 - 1s - loss: 5.2045e-04 - acc: 3.2105e-05 - val_loss: 3.1016e-04 - val_acc: 7.5296e-05\n",
      "Epoch 66/100\n",
      "974/974 - 1s - loss: 5.2443e-04 - acc: 3.2105e-05 - val_loss: 3.2228e-04 - val_acc: 7.5296e-05\n",
      "Epoch 67/100\n",
      "974/974 - 1s - loss: 5.2040e-04 - acc: 3.2105e-05 - val_loss: 3.0481e-04 - val_acc: 7.5296e-05\n",
      "Epoch 68/100\n",
      "974/974 - 1s - loss: 5.2135e-04 - acc: 3.2105e-05 - val_loss: 3.0327e-04 - val_acc: 7.5296e-05\n",
      "Epoch 69/100\n",
      "974/974 - 1s - loss: 5.1880e-04 - acc: 3.2105e-05 - val_loss: 3.9723e-04 - val_acc: 7.5296e-05\n",
      "Epoch 70/100\n",
      "974/974 - 1s - loss: 5.1629e-04 - acc: 3.2105e-05 - val_loss: 3.8234e-04 - val_acc: 7.5296e-05\n",
      "Epoch 71/100\n",
      "974/974 - 1s - loss: 5.3600e-04 - acc: 3.2105e-05 - val_loss: 4.2484e-04 - val_acc: 7.5296e-05\n",
      "Epoch 72/100\n",
      "974/974 - 1s - loss: 5.1823e-04 - acc: 3.2105e-05 - val_loss: 3.0629e-04 - val_acc: 7.5296e-05\n",
      "Epoch 73/100\n",
      "974/974 - 1s - loss: 5.1497e-04 - acc: 3.2105e-05 - val_loss: 3.0228e-04 - val_acc: 7.5296e-05\n",
      "Epoch 74/100\n",
      "974/974 - 1s - loss: 5.2177e-04 - acc: 3.2105e-05 - val_loss: 3.7169e-04 - val_acc: 7.5296e-05\n",
      "Epoch 75/100\n",
      "974/974 - 1s - loss: 5.1345e-04 - acc: 3.2105e-05 - val_loss: 4.2784e-04 - val_acc: 7.5296e-05\n",
      "Epoch 76/100\n",
      "974/974 - 1s - loss: 5.1439e-04 - acc: 3.2105e-05 - val_loss: 3.1880e-04 - val_acc: 7.5296e-05\n",
      "Epoch 77/100\n",
      "974/974 - 1s - loss: 5.1761e-04 - acc: 3.2105e-05 - val_loss: 3.5712e-04 - val_acc: 7.5296e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "974/974 - 1s - loss: 5.2234e-04 - acc: 3.2105e-05 - val_loss: 3.0918e-04 - val_acc: 7.5296e-05\n",
      "Epoch 79/100\n",
      "974/974 - 1s - loss: 5.0911e-04 - acc: 3.2105e-05 - val_loss: 3.6213e-04 - val_acc: 7.5296e-05\n",
      "Epoch 80/100\n",
      "974/974 - 1s - loss: 5.1601e-04 - acc: 3.2105e-05 - val_loss: 3.6336e-04 - val_acc: 7.5296e-05\n",
      "Epoch 81/100\n",
      "974/974 - 1s - loss: 5.2739e-04 - acc: 3.2105e-05 - val_loss: 3.0197e-04 - val_acc: 7.5296e-05\n",
      "Epoch 82/100\n",
      "974/974 - 1s - loss: 5.1014e-04 - acc: 3.2105e-05 - val_loss: 3.0542e-04 - val_acc: 7.5296e-05\n",
      "Epoch 83/100\n",
      "974/974 - 1s - loss: 5.1940e-04 - acc: 3.2105e-05 - val_loss: 3.3677e-04 - val_acc: 7.5296e-05\n",
      "Epoch 84/100\n",
      "974/974 - 1s - loss: 5.1795e-04 - acc: 3.2105e-05 - val_loss: 4.7254e-04 - val_acc: 7.5296e-05\n",
      "Epoch 85/100\n",
      "974/974 - 1s - loss: 5.1411e-04 - acc: 3.2105e-05 - val_loss: 3.0204e-04 - val_acc: 7.5296e-05\n",
      "Epoch 86/100\n",
      "974/974 - 1s - loss: 5.1170e-04 - acc: 3.2105e-05 - val_loss: 5.0354e-04 - val_acc: 7.5296e-05\n",
      "Epoch 87/100\n",
      "974/974 - 1s - loss: 5.2392e-04 - acc: 3.2105e-05 - val_loss: 4.0759e-04 - val_acc: 7.5296e-05\n",
      "Epoch 88/100\n",
      "974/974 - 1s - loss: 5.1311e-04 - acc: 3.2105e-05 - val_loss: 3.3104e-04 - val_acc: 7.5296e-05\n",
      "Epoch 89/100\n",
      "974/974 - 1s - loss: 5.1431e-04 - acc: 3.2105e-05 - val_loss: 3.0038e-04 - val_acc: 7.5296e-05\n",
      "Epoch 90/100\n",
      "974/974 - 1s - loss: 5.1488e-04 - acc: 3.2105e-05 - val_loss: 5.6975e-04 - val_acc: 7.5296e-05\n",
      "Epoch 91/100\n",
      "974/974 - 1s - loss: 5.0995e-04 - acc: 3.2105e-05 - val_loss: 3.0276e-04 - val_acc: 7.5296e-05\n",
      "Epoch 92/100\n",
      "974/974 - 1s - loss: 5.0787e-04 - acc: 3.2105e-05 - val_loss: 3.1781e-04 - val_acc: 7.5296e-05\n",
      "Epoch 93/100\n",
      "974/974 - 1s - loss: 5.1863e-04 - acc: 3.2105e-05 - val_loss: 3.5423e-04 - val_acc: 7.5296e-05\n",
      "Epoch 94/100\n",
      "974/974 - 1s - loss: 5.1381e-04 - acc: 3.2105e-05 - val_loss: 2.9975e-04 - val_acc: 7.5296e-05\n",
      "Epoch 95/100\n",
      "974/974 - 1s - loss: 5.0983e-04 - acc: 3.2105e-05 - val_loss: 3.5489e-04 - val_acc: 7.5296e-05\n",
      "Epoch 96/100\n",
      "974/974 - 1s - loss: 5.2320e-04 - acc: 3.2105e-05 - val_loss: 3.4833e-04 - val_acc: 7.5296e-05\n",
      "Epoch 97/100\n",
      "974/974 - 1s - loss: 5.1139e-04 - acc: 3.2105e-05 - val_loss: 3.0684e-04 - val_acc: 7.5296e-05\n",
      "Epoch 98/100\n",
      "974/974 - 1s - loss: 5.1003e-04 - acc: 3.2105e-05 - val_loss: 3.1522e-04 - val_acc: 7.5296e-05\n",
      "Epoch 99/100\n",
      "974/974 - 1s - loss: 5.1526e-04 - acc: 3.2105e-05 - val_loss: 4.7380e-04 - val_acc: 7.5296e-05\n",
      "Epoch 100/100\n",
      "974/974 - 1s - loss: 5.1054e-04 - acc: 3.2105e-05 - val_loss: 8.9317e-04 - val_acc: 7.5296e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8a5962a2b0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, validation_data=(val_X, val_Y),\n",
    "          verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "\n",
    "trainPredict = model.predict(train_X)\n",
    "valPredict = model.predict(val_X)\n",
    "\n",
    "# Estimate model performance\n",
    "#SInce we used minmaxscaler we can now use scaler.inverse_transform\n",
    "#to invert the transformation.\n",
    "\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY_inverse = scaler.inverse_transform([train_Y])\n",
    "valPredict = scaler.inverse_transform(valPredict)\n",
    "valY_inverse = scaler.inverse_transform([val_Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 13281)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valY_inverse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 1.52 RMSE\n",
      "Test Score: 1.46 RMSE\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY_inverse[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "\n",
    "valScore = math.sqrt(mean_squared_error(valY_inverse[0], valPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (valScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RNN(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set: (31148, 1, 120)\n",
      "Shape of validation set: (13281, 1, 120)\n"
     ]
    }
   ],
   "source": [
    "# Reshape input to be [samples, features, window_size]\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "val_X = np.reshape(val_X, (val_X.shape[0], 1, val_X.shape[1]))\n",
    "\n",
    "print(\"Shape of training set: {}\".format(train_X.shape))\n",
    "print(\"Shape of validation set: {}\".format(val_X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single LSTM with hidden Dense...\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 8)                 4128      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 4,137\n",
      "Trainable params: 4,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Single LSTM with hidden Dense...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(8, input_shape=(None, window_size)))\n",
    "# model.add(Dense(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "#                        verbose=1, mode='auto', restore_best_weights=True)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31148, 1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_Y.reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape input to be [samples, features] (Here time_steps = 1)\n",
    "# train_Y = train_Y.reshape(-1, 1)\n",
    "# val_Y = val_Y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "974/974 - 5s - loss: 0.0047 - val_loss: 9.5677e-04\n",
      "Epoch 2/100\n",
      "974/974 - 2s - loss: 0.0011 - val_loss: 6.1673e-04\n",
      "Epoch 3/100\n",
      "974/974 - 2s - loss: 8.7919e-04 - val_loss: 0.0010\n",
      "Epoch 4/100\n",
      "974/974 - 2s - loss: 7.4909e-04 - val_loss: 4.3837e-04\n",
      "Epoch 5/100\n",
      "974/974 - 2s - loss: 7.3648e-04 - val_loss: 4.4876e-04\n",
      "Epoch 6/100\n",
      "974/974 - 2s - loss: 6.7064e-04 - val_loss: 4.0169e-04\n",
      "Epoch 7/100\n",
      "974/974 - 2s - loss: 6.5661e-04 - val_loss: 3.7889e-04\n",
      "Epoch 8/100\n",
      "974/974 - 2s - loss: 6.2571e-04 - val_loss: 3.7376e-04\n",
      "Epoch 9/100\n",
      "974/974 - 2s - loss: 5.9987e-04 - val_loss: 4.2064e-04\n",
      "Epoch 10/100\n",
      "974/974 - 2s - loss: 6.0999e-04 - val_loss: 3.4612e-04\n",
      "Epoch 11/100\n",
      "974/974 - 2s - loss: 5.9407e-04 - val_loss: 3.7807e-04\n",
      "Epoch 12/100\n",
      "974/974 - 2s - loss: 5.7702e-04 - val_loss: 3.4591e-04\n",
      "Epoch 13/100\n",
      "974/974 - 2s - loss: 5.9316e-04 - val_loss: 5.1105e-04\n",
      "Epoch 14/100\n",
      "974/974 - 2s - loss: 5.6586e-04 - val_loss: 4.5605e-04\n",
      "Epoch 15/100\n",
      "974/974 - 2s - loss: 5.7049e-04 - val_loss: 3.5722e-04\n",
      "Epoch 16/100\n",
      "974/974 - 2s - loss: 5.6941e-04 - val_loss: 5.2389e-04\n",
      "Epoch 17/100\n",
      "974/974 - 2s - loss: 5.6083e-04 - val_loss: 5.1490e-04\n",
      "Epoch 18/100\n",
      "974/974 - 2s - loss: 5.6519e-04 - val_loss: 6.2669e-04\n",
      "Epoch 19/100\n",
      "974/974 - 2s - loss: 5.5544e-04 - val_loss: 9.8204e-04\n",
      "Epoch 20/100\n",
      "974/974 - 2s - loss: 5.6521e-04 - val_loss: 3.3951e-04\n",
      "Epoch 21/100\n",
      "974/974 - 2s - loss: 5.3983e-04 - val_loss: 4.7222e-04\n",
      "Epoch 22/100\n",
      "974/974 - 2s - loss: 5.5099e-04 - val_loss: 3.7475e-04\n",
      "Epoch 23/100\n",
      "974/974 - 2s - loss: 5.4204e-04 - val_loss: 3.2058e-04\n",
      "Epoch 24/100\n",
      "974/974 - 2s - loss: 5.6242e-04 - val_loss: 3.6463e-04\n",
      "Epoch 25/100\n",
      "974/974 - 2s - loss: 5.5615e-04 - val_loss: 3.2870e-04\n",
      "Epoch 26/100\n",
      "974/974 - 2s - loss: 5.4039e-04 - val_loss: 4.9886e-04\n",
      "Epoch 27/100\n",
      "974/974 - 2s - loss: 5.3325e-04 - val_loss: 3.2263e-04\n",
      "Epoch 28/100\n",
      "974/974 - 2s - loss: 5.4250e-04 - val_loss: 8.8957e-04\n",
      "Epoch 29/100\n",
      "974/974 - 2s - loss: 5.3620e-04 - val_loss: 3.5745e-04\n",
      "Epoch 30/100\n",
      "974/974 - 2s - loss: 5.3352e-04 - val_loss: 4.0146e-04\n",
      "Epoch 31/100\n",
      "974/974 - 2s - loss: 5.2645e-04 - val_loss: 4.0336e-04\n",
      "Epoch 32/100\n",
      "974/974 - 2s - loss: 5.2452e-04 - val_loss: 4.6395e-04\n",
      "Epoch 33/100\n",
      "974/974 - 2s - loss: 5.3267e-04 - val_loss: 3.1837e-04\n",
      "Epoch 34/100\n",
      "974/974 - 2s - loss: 5.2742e-04 - val_loss: 3.2662e-04\n",
      "Epoch 35/100\n",
      "974/974 - 2s - loss: 5.2125e-04 - val_loss: 3.4065e-04\n",
      "Epoch 36/100\n",
      "974/974 - 2s - loss: 5.1855e-04 - val_loss: 3.3661e-04\n",
      "Epoch 37/100\n",
      "974/974 - 2s - loss: 5.2043e-04 - val_loss: 6.0868e-04\n",
      "Epoch 38/100\n",
      "974/974 - 2s - loss: 5.2288e-04 - val_loss: 3.2687e-04\n",
      "Epoch 39/100\n",
      "974/974 - 2s - loss: 5.3124e-04 - val_loss: 5.4120e-04\n",
      "Epoch 40/100\n",
      "974/974 - 2s - loss: 5.1986e-04 - val_loss: 5.6048e-04\n",
      "Epoch 41/100\n",
      "974/974 - 2s - loss: 5.1630e-04 - val_loss: 3.1331e-04\n",
      "Epoch 42/100\n",
      "974/974 - 2s - loss: 5.1647e-04 - val_loss: 3.1469e-04\n",
      "Epoch 43/100\n",
      "974/974 - 2s - loss: 5.1463e-04 - val_loss: 3.0660e-04\n",
      "Epoch 44/100\n",
      "974/974 - 2s - loss: 5.2241e-04 - val_loss: 3.1142e-04\n",
      "Epoch 45/100\n",
      "974/974 - 2s - loss: 5.1170e-04 - val_loss: 3.1405e-04\n",
      "Epoch 46/100\n",
      "974/974 - 2s - loss: 5.1286e-04 - val_loss: 3.1298e-04\n",
      "Epoch 47/100\n",
      "974/974 - 2s - loss: 5.1258e-04 - val_loss: 3.1072e-04\n",
      "Epoch 48/100\n",
      "974/974 - 2s - loss: 5.1896e-04 - val_loss: 3.2467e-04\n",
      "Epoch 49/100\n",
      "974/974 - 2s - loss: 5.0712e-04 - val_loss: 3.8388e-04\n",
      "Epoch 50/100\n",
      "974/974 - 2s - loss: 5.1519e-04 - val_loss: 4.4111e-04\n",
      "Epoch 51/100\n",
      "974/974 - 2s - loss: 5.0358e-04 - val_loss: 6.1840e-04\n",
      "Epoch 52/100\n",
      "974/974 - 2s - loss: 5.0431e-04 - val_loss: 3.6777e-04\n",
      "Epoch 53/100\n",
      "974/974 - 2s - loss: 5.0522e-04 - val_loss: 3.7253e-04\n",
      "Epoch 54/100\n",
      "974/974 - 2s - loss: 5.0777e-04 - val_loss: 3.4998e-04\n",
      "Epoch 55/100\n",
      "974/974 - 2s - loss: 4.9841e-04 - val_loss: 5.1290e-04\n",
      "Epoch 56/100\n",
      "974/974 - 3s - loss: 4.9890e-04 - val_loss: 3.1328e-04\n",
      "Epoch 57/100\n",
      "974/974 - 3s - loss: 5.0495e-04 - val_loss: 4.1125e-04\n",
      "Epoch 58/100\n",
      "974/974 - 3s - loss: 4.9805e-04 - val_loss: 3.0334e-04\n",
      "Epoch 59/100\n",
      "974/974 - 3s - loss: 4.9934e-04 - val_loss: 3.3131e-04\n",
      "Epoch 60/100\n",
      "974/974 - 2s - loss: 5.0148e-04 - val_loss: 3.2066e-04\n",
      "Epoch 61/100\n",
      "974/974 - 2s - loss: 4.9905e-04 - val_loss: 3.8912e-04\n",
      "Epoch 62/100\n",
      "974/974 - 2s - loss: 5.0022e-04 - val_loss: 3.2998e-04\n",
      "Epoch 63/100\n",
      "974/974 - 2s - loss: 4.9833e-04 - val_loss: 3.9635e-04\n",
      "Epoch 64/100\n",
      "974/974 - 2s - loss: 4.9807e-04 - val_loss: 3.2137e-04\n",
      "Epoch 65/100\n",
      "974/974 - 2s - loss: 5.0044e-04 - val_loss: 4.9209e-04\n",
      "Epoch 66/100\n",
      "974/974 - 2s - loss: 4.8922e-04 - val_loss: 3.7777e-04\n",
      "Epoch 67/100\n",
      "974/974 - 2s - loss: 5.0093e-04 - val_loss: 3.0396e-04\n",
      "Epoch 68/100\n",
      "974/974 - 2s - loss: 4.9102e-04 - val_loss: 3.4708e-04\n",
      "Epoch 69/100\n",
      "974/974 - 2s - loss: 4.9489e-04 - val_loss: 4.4731e-04\n",
      "Epoch 70/100\n",
      "974/974 - 2s - loss: 4.9652e-04 - val_loss: 3.8825e-04\n",
      "Epoch 71/100\n",
      "974/974 - 2s - loss: 5.0372e-04 - val_loss: 3.5359e-04\n",
      "Epoch 72/100\n",
      "974/974 - 2s - loss: 4.8790e-04 - val_loss: 3.0433e-04\n",
      "Epoch 73/100\n",
      "974/974 - 2s - loss: 4.9821e-04 - val_loss: 3.1898e-04\n",
      "Epoch 74/100\n",
      "974/974 - 2s - loss: 4.9050e-04 - val_loss: 3.1094e-04\n",
      "Epoch 75/100\n",
      "974/974 - 2s - loss: 4.9300e-04 - val_loss: 3.1137e-04\n",
      "Epoch 76/100\n",
      "974/974 - 2s - loss: 4.9387e-04 - val_loss: 3.2098e-04\n",
      "Epoch 77/100\n",
      "974/974 - 2s - loss: 4.9080e-04 - val_loss: 2.9885e-04\n",
      "Epoch 78/100\n",
      "974/974 - 2s - loss: 4.9334e-04 - val_loss: 3.0374e-04\n",
      "Epoch 79/100\n",
      "974/974 - 2s - loss: 4.8630e-04 - val_loss: 3.1725e-04\n",
      "Epoch 80/100\n",
      "974/974 - 2s - loss: 4.9302e-04 - val_loss: 3.0621e-04\n",
      "Epoch 81/100\n",
      "974/974 - 2s - loss: 4.8890e-04 - val_loss: 4.8596e-04\n",
      "Epoch 82/100\n",
      "974/974 - 2s - loss: 4.9385e-04 - val_loss: 3.0339e-04\n",
      "Epoch 83/100\n",
      "974/974 - 2s - loss: 4.8669e-04 - val_loss: 5.9230e-04\n",
      "Epoch 84/100\n",
      "974/974 - 2s - loss: 4.8516e-04 - val_loss: 3.4214e-04\n",
      "Epoch 85/100\n",
      "974/974 - 2s - loss: 4.8965e-04 - val_loss: 3.2651e-04\n",
      "Epoch 86/100\n",
      "974/974 - 2s - loss: 4.8619e-04 - val_loss: 3.3712e-04\n",
      "Epoch 87/100\n",
      "974/974 - 2s - loss: 4.9866e-04 - val_loss: 3.8986e-04\n",
      "Epoch 88/100\n",
      "974/974 - 2s - loss: 4.8474e-04 - val_loss: 3.3213e-04\n",
      "Epoch 89/100\n",
      "974/974 - 2s - loss: 4.8219e-04 - val_loss: 3.7082e-04\n",
      "Epoch 90/100\n",
      "974/974 - 2s - loss: 4.9261e-04 - val_loss: 3.6743e-04\n",
      "Epoch 91/100\n",
      "974/974 - 2s - loss: 4.7992e-04 - val_loss: 3.6940e-04\n",
      "Epoch 92/100\n",
      "974/974 - 3s - loss: 4.8404e-04 - val_loss: 7.0296e-04\n",
      "Epoch 93/100\n",
      "974/974 - 2s - loss: 4.9157e-04 - val_loss: 3.1455e-04\n",
      "Epoch 94/100\n",
      "974/974 - 2s - loss: 4.8124e-04 - val_loss: 3.3636e-04\n",
      "Epoch 95/100\n",
      "974/974 - 2s - loss: 4.7301e-04 - val_loss: 3.5674e-04\n",
      "Epoch 96/100\n",
      "974/974 - 3s - loss: 4.8031e-04 - val_loss: 4.8804e-04\n",
      "Epoch 97/100\n",
      "974/974 - 2s - loss: 4.7760e-04 - val_loss: 3.4926e-04\n",
      "Epoch 98/100\n",
      "974/974 - 2s - loss: 4.7593e-04 - val_loss: 2.9898e-04\n",
      "Epoch 99/100\n",
      "974/974 - 2s - loss: 4.8464e-04 - val_loss: 3.0432e-04\n",
      "Epoch 100/100\n",
      "974/974 - 2s - loss: 4.9269e-04 - val_loss: 3.0762e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8a5e933e80>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, validation_data=(val_X, val_Y),\n",
    "          verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "\n",
    "trainPredict = model.predict(train_X)\n",
    "valPredict = model.predict(val_X)\n",
    "\n",
    "# Estimate model performance\n",
    "#SInce we used minmaxscaler we can now use scaler.inverse_transform\n",
    "#to invert the transformation.\n",
    "\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([train_Y])\n",
    "valPredict = scaler.inverse_transform(valPredict)\n",
    "valY = scaler.inverse_transform([val_Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 1.03 RMSE\n",
      "Test Score: 0.86 RMSE\n"
     ]
    }
   ],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "\n",
    "valScore = math.sqrt(mean_squared_error(valY[0], valPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (valScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df_for_training)\n",
    "df_for_training_scaled = scaler.transform(df_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_training_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape == (857, 120, 3).\n",
      "trainY shape == (857, 1).\n"
     ]
    }
   ],
   "source": [
    "#As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features. \n",
    "#In this example, the n_features is 2. We will make timesteps = 3. \n",
    "#With this, the resultant n_samples is 5 (as the input data has 9 rows).\n",
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "n_future = 24   # Number of days we want to predict into the future\n",
    "n_past = 24*5     # Number of past days we want to use to predict the future\n",
    "\n",
    "for i in range(n_past, len(df_for_training_scaled) - n_future +1):\n",
    "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])\n",
    "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "\n",
    "print('trainX shape == {}.'.format(trainX.shape))\n",
    "print('trainY shape == {}.'.format(trainY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 120, 8)            384       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 120, 1)            9         \n",
      "=================================================================\n",
      "Total params: 393\n",
      "Trainable params: 393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(8, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 137ms/step - loss: 0.8938 - val_loss: 1.4555\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.7869 - val_loss: 1.4548\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.7750 - val_loss: 1.4560\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.7594 - val_loss: 1.4571\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.7217 - val_loss: 1.4607\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.7764 - val_loss: 1.4655\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.6987 - val_loss: 1.4694\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.7556 - val_loss: 1.4747\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.7517 - val_loss: 1.4782\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.7644 - val_loss: 1.4837\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = model.fit(trainX, trainY, epochs=10, batch_size=128, validation_split=0.3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Forecasting...\n",
    "# #Start with the last day in training date and predict future...\n",
    "# n_future=24  #Redefining n_future to extend prediction dates beyond original n_future dates...\n",
    "# train_dates = pd.to_datetime(df['datetime'])\n",
    "# forecast_period_dates = pd.date_range(list(train_dates)[-1], periods=n_future, freq='1d').tolist()\n",
    "\n",
    "forecast = model.predict(trainX) #forecast \n",
    "\n",
    "#Perform inverse transformation to rescale back to original range\n",
    "#Since we used 5 variables for transform, the inverse expects same dimensions\n",
    "#Therefore, let us copy our values 5 times and discard them after inverse transform\n",
    "forecast_copies = np.repeat(forecast, df_for_training.shape[1], axis=-1)\n",
    "y_pred_future = scaler.inverse_transform(forecast_copies)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(857, 3)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_future.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(857, 120, 1)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.499452  , 0.5264093 , 0.57623946, ..., 0.4296081 , 0.41041123,\n",
       "       0.4044888 ])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (93444,) (3,) (93444,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-e51df0142a9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mforecast_copies_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_for_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred_future_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast_copies_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (93444,) (3,) (93444,) "
     ]
    }
   ],
   "source": [
    "forecast_copies_Y = np.repeat(train_Y, df_for_training.shape[1], axis=-1)\n",
    "y_pred_future_Y = scaler.inverse_transform(forecast_copies_Y)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-8160fe94434d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mforecast_dates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_forecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Temperature'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_pred_future\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf_forecast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_forecast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             val = sanitize_array(\n\u001b[0m\u001b[1;32m    352\u001b[0m                 \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# Convert timestamp to date\n",
    "forecast_dates = []\n",
    "for time_i in forecast_period_dates:\n",
    "    forecast_dates.append(time_i.date())\n",
    "    \n",
    "df_forecast = pd.DataFrame({'Date':np.array(forecast_dates), 'Temperature':y_pred_future})\n",
    "df_forecast['Date']=pd.to_datetime(df_forecast['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = df[['Date', 'Open']]\n",
    "original['Date']=pd.to_datetime(original['Date'])\n",
    "original = original.loc[original['Date'] >= '2020-5-1']\n",
    "\n",
    "sns.lineplot(original['Date'], original['Open'])\n",
    "sns.lineplot(df_forecast['Date'], df_forecast['Open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44551, 120, 2)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44551, 1)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44551, 120, 1)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast = model.predict(trainX) #forecast \n",
    "forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-d2b78df778df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Therefore, let us copy our values 5 times and discard them after inverse transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mforecast_copies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_for_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_pred_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast_copies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[0m\u001b[1;32m    459\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    657\u001b[0m                     \"into decimal numbers with dtype='numeric'\") from e\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0m\u001b[1;32m    660\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "#Perform inverse transformation to rescale back to original range\n",
    "#Since we used 5 variables for transform, the inverse expects same dimensions\n",
    "#Therefore, let us copy our values 5 times and discard them after inverse transform\n",
    "forecast_copies = np.repeat(forecast, df_for_training.shape[1], axis=-1)\n",
    "y_pred_future = scaler.inverse_transform(forecast_copies)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
